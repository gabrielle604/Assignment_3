---
title: "Assignment 3"
author: "Gabrielle"
date: '2022-11-09'
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning = FALSE,results=FALSE)

library(knitr)
library(tidyverse)
library(here)
library(ggpubr) # for some graphic applications that extend ggplot2
library(janitor)
# install.packages("lsr")
library(lsr)
library(effsize)
library(dplyr)
# install.packages("qqplotr")
library(qqplotr)
library(ggplot2)
# install.packages("DescTools")
library(DescTools)
# install.packages("broom")
library(broom)

```

## 1
In order to determine if the current population in the San Antonio River in Santa Barbara County is different from the historical record, I did a one sample t-test, and set mu to equal 4.2 cm (rather than the default, mu = 0), the value from the 1955 document that reported the population mean length of adult tidewater gobies. I did this because I am testing to see if there is a statistical difference between the historical mean length of gobies, and the current mean length of gobies (3.5 cm). The one-sample t-test allows us to compare the mean from sample data to a value, usually testing literature point estimates. This test does assume equal variance. 
I found a statistical difference between the current San Antonio goby fish mean length, and the historical 1955 goby population mean length (t(9 df), p = 0.0008873), ⍺ = 0.05.
CI: 3.189284, 3.830716

```{r, message=FALSE}
# San Antonio River gobies in centimeters  
# data input: creating a vector of data
san_ant_gobies <- c(2.7, 3.2, 3.2, 3.3, 3.5, 3.6, 3.6, 3.7, 4.0, 4.3)

summary(san_ant_gobies)

san_ant_gobies_one_t <- t.test(san_ant_gobies, mu=4.2)
san_ant_gobies_one_t
```


## 2
To determine whether the tidewater goby lengths in question 1 are normally distributed, I carried out a Shapiro-Wilks normaltiy test. W = 0.97657, p = 0.9442. Since this value from the Shapiro Wilk's test is not less than .05, I can assume the sample data comes from a population that is normally distributed.

```{r}
shapiro.test(san_ant_gobies)
```

Alternative approach:
For this data, to look at whether the tidewater goby lengths are normally distributed, we're going to look at a qq plot. It should be mostly a straight line, however, due to there being very few observations (n=10),  some wobble to the line is expected. 

```{r goby_1, fig.align='center',fig.cap="Figure 1. Quantile-Quantile plot showing the empirically observed quantiles of San Antonio River Gobies (cm) as a function of quantiles expected from a normal distribution with the same mean and variance as the empirical distribution."}

qqplot_san_ant_gobies <- ggplot(data.frame(san_ant_gobies), 
                         aes(sample = san_ant_gobies)) + 
                         geom_qq() + 
                         labs(title = "San Antonio River Gobies") +
                         theme_minimal() +
                         stat_qq() +
                         geom_qq_line()

qqplot_san_ant_gobies
```


## 3
The UC Tobacco Free Campus Initiative wants to know if the UC reserves have more or less cigarette butt load as urban open spaces. I determined that the number of cigarette butts at the UC reserve is  statistically significantly less than the number of cigarrette butts in Urban Open Space (p = 7.607e-07, α = 0.05.)

The non-parametric, Mann-Whitney U test (called Wilcox test in R) is the appropriate statistical test because the data is not normal; it is skewed - this was observed through looking at the qq plots of residuals and the shapiro wilks tests. 
The Wilcox test in R is the pairwise comparison analogous to the Tukey HSD by looking at pairwise Wilcox tests that have been adjusted for multiple comparison, a type of continuity correction.

Since non-parametric evaluations are largely based on comparing medians instead of means, it is important to plot the results using box plots instead of means and 95% confidence intervals as done parametrically.

Mann Whitney U is an unpaired test of medians, whereas Wilcoxon is paired tests of medians between two groups. The default setting is, paired = FALSE, comparing independent unpaired samples together. 

```{r, fig.show='hide'}
uc_reserves <- data.frame(cig_butts=c(4, 1, 8, 0, 0, 0, 0, 23, 28, 0, 0, 0, 4, 0, 3, 0, 0, 2, 0, 5, 0, 0, 0, 0, 0),location="Reserve")


urban_open <- data.frame(cig_butts=c(33, 9, 9, 7, 2, 38, 9, 20, 0, 39, 18, 41, 25, 164, 37, 60, 55, 45, 14, 3, 69, 60, 13, 1), location="Urban Open Space")

cig_df <- rbind(uc_reserves, urban_open)

qqplot_uc_reserves <- ggplot((uc_reserves), aes(sample = cig_butts)) +
  geom_qq() +
  labs(title = "UC Reserves") +
  theme_minimal() +
  stat_qq() +
  geom_qq_line()

qqplot_uc_reserves

shapiro.test(uc_reserves$cig_butts)

qqplot_urban_open <- ggplot((urban_open), aes(sample = cig_butts)) +
  geom_qq() +
  labs(title = "Urban Open Space") +
  theme_minimal() +
  stat_qq() +
  geom_qq_line()

qqplot_urban_open

shapiro.test(urban_open$cig_butts)

pairwise.wilcox.test(cig_df$cig_butts, cig_df$location)

wilcox.test(uc_reserves$cig_butts, urban_open$cig_butts, paired = FALSE)

```


```{r cig_load_1, fig.align='center',fig.cap="Figure 2. Boxplot showing cigarette butt load for the UC Reserve and for Urban Open Space, the boxes marking quantile 1, the median, quantile 3, and the dots denote the outliers."}
boxplot_cig_load <- ggplot(data = cig_df, aes(x = location, y = cig_butts)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Cigarette Butt Load", x = "Location", y = "Cigarette Butts")

boxplot_cig_load
```

## 4
There is conclusive evidence that this new species of turtles' time between laid egg and hatching is temperature dependent. In order to determine this, first I visually inspected a scatter plot of the data (Figure 3), observing that there is a negative relationship between the number of days between laid egg and hatching and the temperature of the eggs being incubated. Then, I separated the data into four groups: 15C, 20C, 25C, 30C. Temperature is typically a continuous variable, but in this study, it is being used as a "treatment" for the eggs, and it is being forced into a discrete variable.

Since there are four groups, and the data appears to meet the assumptions of normality, One of the groups, temperature 25C, is a bit off-normal, however, it is okay because no data is ever perfect, and it performs alright on the shapiro test. 

I chose to do a parametric test: the anova test. 

I tested for normality by visually inspecting qq plots and the shapiro test for each temperature group. Since these values from the Shapiro Wilk's tests are not less than .05, we can assume the sample data comes from a population that is normally distributed. I looked at the variances (Levene's Test) and we can fail to reject the null hypothesis, so we can operate as though the variances are equal, which adds credibility to my decision to go with an anova test. 

I carried out Tukey's test, which accounts/provides a penalty for doing a bunch of comparisons between groups, and deflates the p value to minimize risk of Type I error, rejecting the null hypothesis when it is actually true.

```{r turtles_1, fig.align='center',fig.cap="Figure 3. Scatter plot showing the relationship between temperature and number of days to turtle egg hatching. The higher the temperature, the fewer days until hatching occurs."}
# Load in the data:

turtles <- read_csv(here("data", "Turtles.csv"))

turtles_scatter <- ggplot(turtles, aes(x = Temperature, y = Days)) +
  geom_point() +
  labs(title = "New Turtle Species", x = "Temperature (C)", y = "Days") +
  geom_smooth(formula = y~x, method = lm) +
  theme_minimal()

turtles_scatter

# do summary statistics for each of these - do I expect to see a difference? YES
turtles_15c <- turtles %>% filter(Temperature == "15")
summary(turtles_15c)

turtles_20c <- turtles %>% filter(Temperature == "20")
summary(turtles_20c)

turtles_25c <- turtles %>% filter(Temperature == "25")
summary(turtles_25c)

turtles_30c <- turtles %>% filter(Temperature == "30")
summary(turtles_30c)

```

```{r, fig.show='hide'}
# qq plot and shapiro test for each
qqplot_15c <- ggplot(turtles_15c, 
                     aes(sample = Days)) +
                     geom_qq() +
                     labs(title = "Turtles at 15C") +
                     theme_minimal() +
                     stat_qq() +
                     geom_qq_line()
qqplot_15c

shapiro.test(turtles_15c$Days)

qqplot_20c <- ggplot(turtles_20c, 
                     aes(sample = Days)) +
                     geom_qq() +
                     labs(title = "Turtles at 20C") +
                     theme_minimal() +
                     stat_qq() +
                     geom_qq_line()
qqplot_20c

shapiro.test(turtles_20c$Days)

qqplot_25c <- ggplot(turtles_25c, 
                     aes(sample = Days)) +
                     geom_qq() +
                     labs(title = "Turtles at 25C") +
                     theme_minimal() +
                     stat_qq() +
                     geom_qq_line()
qqplot_25c

shapiro.test(turtles_25c$Days)

qqplot_30c <- ggplot(turtles_30c, 
                     aes(sample = Days)) +
                     geom_qq() +
                     labs(title = "Turtles at 30C") +
                     theme_minimal() +
                     stat_qq() +
                     geom_qq_line()
qqplot_30c

shapiro.test(turtles_30c$Days)


LeveneTest(Days ~ as.factor(Temperature), data = turtles)

```

```{r, fig.show='hide'}
m_turtles_results <- aov(Days ~ as.factor(Temperature), data = turtles)

m_turtles_results

summary(m_turtles_results)

TukeyHSD(m_turtles_results)

# We are able to look at the residual plots using the plot() command. Showing residual vs. fitted shows the distribution of turtle egg incubation time in days. These are the diagnostics. 
# suppress plots or comment out
plot(m_turtles_results)

#RESIDUAL PLOT: the red line is showing you the trend in the data 
#Q-Q PLOT: taking the residuals and giving you a Q-Q plot right away for inspection
#SCALE LOCATION: (not used much)… it flags heteroskedasticity; some outliers are a bit farther away… you want to see a flat line
#Cook’s distance: A measure of how much influence a single observation has on your model; could consider removing a data point to see if it improves the cook’s distance BECAUSE you think it is an outlier; cooks distance of 2 isn’t terrible, but 4, 5, and up are not good

```


```{r turtles_2, fig.align='center',fig.cap="Figure 4. Plot showing turtles data. Displayed are the means of each incubation temperature with the 95% confidence intervals. As the temperatures increase, we see that the days until turtle egg hatching decreases.Using the ANOVA test, we find this difference to be statistically significant, f value = 15.98, p = 9.08e-07, α = 0.05."}

ggline(turtles, x = "Temperature", y = "Days", 
       main = "Means days of incubation for turtle eggs in each temperature and 95% CI", 
       add = c("mean_ci"), 
       color = "dark gray", 
       ylab = "Days", 
       xlab = "Temperature", 
       point.color = "blue")
```


```{r, results = TRUE}
out_m_turtles_results_tidy <- tidy(m_turtles_results) # for the coefficient output
out_m_turtles_results_glance <- glance(m_turtles_results) # for the model output

kable(out_m_turtles_results_tidy, format = "markdown", digits = 3, caption = "Analysis of variance table for new turtle species model")

# kable(out_m_turtles_results_glance, format = "markdown", digits = 3, caption = "ANOVA test for turtle model ")

```


